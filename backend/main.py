"""
Mirqab Backend - Main FastAPI Application
Automatic AI Report Generation with Complete PDF Export Support
"""

from fastapi import FastAPI, File, UploadFile, Form, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import FileResponse, JSONResponse
from PIL import Image
import io
import json
import base64
import uuid
from datetime import datetime
import numpy as np
import cv2
import tempfile
import os
from pathlib import Path
from dotenv import load_dotenv

# âœ… NEW: Load environment variables from project root (not from backend directory)
root_dir = Path(__file__).parent.parent
env_path = root_dir / '.env'
print(f"Loading environment from: {env_path}")
print(f".env exists: {env_path.exists()}")
load_dotenv(dotenv_path=env_path)

# Verify environment is loaded
api_key = os.getenv('OPENAI_API_KEY')
print(f"OpenAI API Key loaded: {bool(api_key)}")

from model_handler import SegmentationModel
from llm_handler import LLMReportGenerator
from utils import detect_soldiers, encode_image_to_base64, overlay_mask_on_image
from firestore_handler import firestore_handler
from firebase_storage_handler import firebase_storage_handler
from moraqib_rag import initialize_rag

app = FastAPI(title="Mirqab API")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

model = SegmentationModel()
llm = LLMReportGenerator()

# Initialize Moraqib RAG system
moraqib_rag = None

# API Key for Raspberry Pi authentication
MIRQAB_API_KEY = os.getenv("MIRQAB_API_KEY", "development-key-change-in-production")

@app.on_event("startup")
async def startup_event():
    global moraqib_rag
    
    print("ðŸš€ Starting Mirqab Backend...")
    model.load_model()
    
    # Initialize Firestore
    if os.getenv("FIREBASE_CREDENTIALS_PATH"):
        firestore_handler.initialize()
        firebase_storage_handler.initialize()
        
        # Initialize Moraqib RAG system
        moraqib_rag = initialize_rag(firestore_handler)
        print("âœ… Moraqib RAG system initialized")
    else:
        print("âš ï¸  Firebase credentials not configured - Pi reporting disabled")
        print("âš ï¸  Moraqib RAG system disabled")
    
    print("âœ… Ready for automatic AI report generation!")

@app.get("/health")
async def health_check():
    return {
        "status": "healthy",
        "model_loaded": model.is_loaded(),
        "openai_api_available": llm.check_connection()  # âœ… Changed from gemini_api_available
    }

@app.post("/api/analyze_media")
async def analyze_media(
    file: UploadFile = File(...),
    location: str = Form(None)
):
    """
    Complete image analysis with automatic AI report generation and PDF support.
    Returns full report structure compatible with ReportModal and PDF generator.
    """
    try:
        # Parse location
        location_data = json.loads(location) if location else {"lat": "N/A", "lng": "N/A"}
        
        # Read and prepare image
        contents = await file.read()
        image = Image.open(io.BytesIO(contents)).convert("RGB")
        
        # Perform soldier detection
        print("ðŸ” Analyzing image for camouflaged soldiers...")
        mask, instances = model.predict(image)
        
        # Count soldiers, civilians, and total from mask (DeepLabV3 semantic segmentation)
        soldier_count = 0
        civilian_count = 0
        total_detections = 0
        
        # For DeepLabV3, instances is actually the segmentation map
        # Count soldiers from connected components in the binary mask
        if np.any(mask > 0):
            num_labels, labels, stats, _ = cv2.connectedComponentsWithStats(mask, connectivity=8)
            min_area = 100
            soldier_count = sum(1 for i in range(1, num_labels) if stats[i, cv2.CC_STAT_AREA] >= min_area)
            total_detections = soldier_count
            # DeepLabV3 doesn't detect civilians in this configuration
            civilian_count = 0
        
        # Generate detection objects for API response (always uses instances)
        detections = detect_soldiers(mask, instances)
        
        print(f"âœ… Detection complete:")
        print(f"   - Camouflage soldiers: {soldier_count}")
        print(f"   - Civilians: {civilian_count}")
        print(f"   - Total detections: {total_detections}")
        
        # Create overlay image
        overlay_image = overlay_mask_on_image(image, mask)
        overlay_base64 = encode_image_to_base64(overlay_image)
        
        # Encode original image with data URI prefix
        buffered = io.BytesIO()
        image.save(buffered, format="JPEG")
        original_base64 = f"data:image/jpeg;base64,{base64.b64encode(buffered.getvalue()).decode('utf-8')}"
        
        # Generate AI analysis automatically
        ai_analysis = None
        if soldier_count > 0:
            print(f"ðŸ¤– Generating AI analysis report...")
            try:
                ai_analysis = await llm.generate_report(image)
                print("âœ… AI analysis complete!")
            except Exception as e:
                print(f"âš ï¸ AI analysis failed ({str(e)}), using fallback report")
                ai_analysis = {
                    "summary": f"Detected {soldier_count} camouflaged soldier(s) in the analyzed area. Advanced pattern recognition identified military camouflage patterns.",
                    "environment": "Environment analysis unavailable (LLM offline)",
                    "camouflaged_soldier_count": soldier_count,
                    "soldier_count": soldier_count,
                    "has_camouflage": True,
                    "attire_and_camouflage": "Military camouflage pattern detected",
                    "equipment": "Unable to determine specific equipment (LLM offline)"
                }
        else:
            # No soldiers detected
            ai_analysis = {
                "summary": "No camouflaged soldiers detected in the analyzed area.",
                "environment": "Clear area",
                "camouflaged_soldier_count": 0,
                "has_camouflage": False,
                "attire_and_camouflage": "N/A",
                "equipment": "N/A"
            }
        
        # Check if camouflage was detected - ONLY save reports with camouflaged soldiers
        has_camouflage = ai_analysis.get("has_camouflage", False)
        camouflaged_count = ai_analysis.get("camouflaged_soldier_count", ai_analysis.get("soldier_count", soldier_count))
        
        # If we detected soldiers but AI analysis failed, still consider it camouflage
        if soldier_count > 0 and camouflaged_count == 0:
            camouflaged_count = soldier_count
            has_camouflage = True
        
        if not has_camouflage or camouflaged_count == 0:
            print("âš ï¸ No camouflaged soldiers detected - skipping report creation")
            return {
                "success": False,
                "message": "No camouflaged soldiers detected. Only camouflaged military personnel are tracked.",
                "has_camouflage": False,
                "detection": False,
                "soldier_count": 0,
                "civilian_count": civilian_count,
                "total_detections": total_detections
            }
        
        # Generate Firestore report first to get the proper report ID
        timestamp = datetime.now().isoformat()
        
        # Format location for report
        report_location = None
        if location_data.get("lat") != "N/A" and location_data.get("lng") != "N/A":
            report_location = {
                "latitude": float(location_data["lat"]),
                "longitude": float(location_data["lng"])
            }
        else:
            report_location = {"latitude": 0, "longitude": 0}
        
        # Save report to Firestore database FIRST to get the proper report ID
        report_id = None
        if firestore_handler.db:
            try:
                print("ðŸ’¾ Saving report to Firestore database...")
                firestore_report_data = {
                    "longitude": report_location["longitude"],
                    "latitude": report_location["latitude"],
                    "environment": ai_analysis.get("environment", "Unknown"),
                    "soldier_count": ai_analysis.get("camouflaged_soldier_count", ai_analysis.get("soldier_count", camouflaged_count)),
                    "attire_and_camouflage": ai_analysis.get("attire_and_camouflage", ai_analysis.get("attire", "Unknown")),
                    "equipment": ai_analysis.get("equipment", "Unknown"),
                    "source_device_id": "Web-Upload"
                }
                report_id = firestore_handler.create_detection_report(firestore_report_data)
                if report_id:
                    print(f"âœ… Report saved to Firestore: {report_id}")
                    
                    # Upload images to Firebase Storage
                    if firebase_storage_handler._initialized:
                        print("ðŸ“¸ Uploading images to Firebase Storage...")
                        try:
                            original_url = firebase_storage_handler.upload_image(original_base64, report_id, "original")
                            segmented_url = firebase_storage_handler.upload_image(overlay_base64, report_id, "segmented")
                            
                            # Update Firestore with image URLs
                            if original_url or segmented_url:
                                firestore_handler.db.collection('detection_reports').document(report_id).update({
                                    'image_snapshot_url': original_url or '',
                                    'segmented_image_url': segmented_url or ''
                                })
                                print(f"âœ… Images uploaded and URLs updated in Firestore")
                            else:
                                print("âš ï¸ Failed to upload images to Firebase Storage - bucket may not exist")
                                print("ðŸ’¡ To fix: Enable Firebase Storage in Firebase Console")
                        except Exception as e:
                            print(f"âš ï¸ Firebase Storage upload failed: {e}")
                            print("ðŸ’¡ To fix: Enable Firebase Storage in Firebase Console")
                    else:
                        print("âš ï¸ Firebase Storage not initialized - skipping image upload")
                else:
                    print("âš ï¸ Failed to save report to Firestore")
                    # Fallback to UUID if Firestore fails
                    report_id = str(uuid.uuid4())[:8].upper()
            except Exception as e:
                print(f"âš ï¸ Error saving to Firestore: {e}")
                # Fallback to UUID if Firestore fails
                report_id = str(uuid.uuid4())[:8].upper()
        else:
            print("âš ï¸ Firestore not initialized - using temporary report ID")
            # Fallback to UUID if Firestore not available
            report_id = str(uuid.uuid4())[:8].upper()
        
        # Build complete report object with the Firestore report ID
        # Use Firebase field names for consistency
        report_analysis = {
            "summary": ai_analysis.get("summary", ""),
            "environment": ai_analysis.get("environment", "Unknown"),
            "soldier_count": ai_analysis.get("camouflaged_soldier_count", ai_analysis.get("soldier_count", camouflaged_count)),
            "attire_and_camouflage": ai_analysis.get("attire_and_camouflage", ai_analysis.get("attire", "Unknown")),
            "equipment": ai_analysis.get("equipment", "Unknown")
        }
        
        report = {
            "report_id": report_id,
            "timestamp": timestamp,
            "location": report_location,
            "analysis": report_analysis,
            "images": {
                "original_base64": original_base64,
                "masked_base64": overlay_base64
            }
        }
        
        # Return response with both detection data AND complete report
        return {
            "success": True,
            "detection": True,
            "has_camouflage": True,
            "soldier_count": camouflaged_count,
            "civilian_count": civilian_count,
            "total_detections": total_detections,
            "detections": detections,
            "overlay_image": overlay_base64,
            "original_image": original_base64,
            "report": report,  # Complete report for ReportModal and PDF
            "class_breakdown": {
                "camouflage_soldiers": soldier_count,
                "civilians": civilian_count,
                "total": total_detections
            }
        }
    
    except Exception as e:
        print(f"âŒ Error in analyze_media: {str(e)}")
        import traceback
        traceback.print_exc()
        return {
            "success": False,
            "error": str(e),
            "detection": False
        }

@app.get("/api/detection-reports")
async def get_detection_reports(
    time_range: str = "24h",
    limit: int = 100,
    offset: int = 0
):
    """
    Get detection reports for the Detection Reports dashboard
    """
    try:
        if not firestore_handler.db:
            return {
                "success": False,
                "error": "Firestore not initialized",
                "detections": []
            }
        
        print(f"ðŸ“Š Fetching detection reports (time_range: {time_range}, limit: {limit})")
        
        # Get reports from Firestore
        reports = firestore_handler.get_detection_reports(
            time_range=time_range,
            limit=limit,
            offset=offset
        )
        
        # Transform reports to match frontend interface
        detections = []
        for report in reports:
            location = report.get("location", {})
            detection = {
                "report_id": report.get("report_id", ""),
                "timestamp": report.get("timestamp", ""),
                "location": {
                    "latitude": location.get("latitude", 0),
                    "longitude": location.get("longitude", 0)
                },
                "soldier_count": report.get("soldier_count", 0),
                "attire_and_camouflage": report.get("attire_and_camouflage", "Unknown"),
                "environment": report.get("environment", "Unknown"),
                "equipment": report.get("equipment", "Unknown"),
                "image_snapshot_url": report.get("image_snapshot_url", ""),
                "source_device_id": report.get("source_device_id", ""),
                "segmented_image_url": report.get("segmented_image_url", ""),
                # Additional SOC fields
                "severity": "High" if report.get("soldier_count", 0) >= 3 else "Medium" if report.get("soldier_count", 0) >= 2 else "Low",
                "status": "New",
                "assignee": "Unassigned"
            }
            detections.append(detection)
        
        print(f"âœ… Retrieved {len(detections)} detection reports")
        
        return {
            "success": True,
            "detections": detections,
            "total": len(detections),
            "time_range": time_range
        }
        
    except Exception as e:
        print(f"âŒ Error fetching detection reports: {e}")
        import traceback
        traceback.print_exc()
        return {
            "success": False,
            "error": str(e),
            "detections": []
        }

@app.get("/api/detection-stats")
async def get_detection_stats(time_range: str = "24h"):
    """
    Get detection statistics for KPI cards
    """
    try:
        if not firestore_handler.db:
            return {
                "success": False,
                "error": "Firestore not initialized",
                "stats": {}
            }
        
        print(f"ðŸ“ˆ Fetching detection statistics (time_range: {time_range})")
        
        # Get reports for statistics
        reports = firestore_handler.get_detection_reports(time_range=time_range, limit=1000)
        
        total_detections = len(reports)
        critical_alerts = sum(1 for r in reports if r["soldier_count"] >= 3)
        
        # Calculate MTTD and MTTR (mock values for now)
        mttd = "4.5 Hours"
        mttr = "2.1 Days"
        
        # Count by status (mock for now)
        alerts_by_status = {
            "new": total_detections,
            "inProgress": 0,
            "closed": 0
        }
        
        stats = {
            "totalDetections": total_detections,
            "criticalAlerts": critical_alerts,
            "mttd": mttd,
            "mttr": mttr,
            "alertsByStatus": alerts_by_status
        }
        
        print(f"âœ… Retrieved detection statistics: {stats}")
        
        return {
            "success": True,
            "stats": stats
        }
        
    except Exception as e:
        print(f"âŒ Error fetching detection stats: {e}")
        return {
            "success": False,
            "error": str(e),
            "stats": {}
        }
@app.post("/api/test_segmentation")
async def test_segmentation(file: UploadFile = File(...)):
    """
    Lightweight segmentation for test mode - ONLY returns overlay mask.
    No AI analysis, no reports, no detection counting - just pure segmentation visualization.
    """
    try:
        print("ðŸ§ª Test segmentation (overlay only)...")
        
        # Read uploaded image
        contents = await file.read()
        nparr = np.frombuffer(contents, np.uint8)
        image = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        pil_image = Image.fromarray(image_rgb)
        
        # Run segmentation to get binary mask (ignore instances for test mode)
        mask, _ = model.predict(pil_image)
        
        # Create overlay image using utility function
        overlay_image = overlay_mask_on_image(pil_image, mask, alpha=0.5)
        
        # Convert to base64
        buffered = io.BytesIO()
        overlay_image.save(buffered, format="JPEG", quality=70)
        overlay_base64 = f"data:image/jpeg;base64,{base64.b64encode(buffered.getvalue()).decode('utf-8')}"
        
        print("âœ… Test overlay generated")
        return {
            "success": True,
            "overlay_image": overlay_base64
        }
    
    except Exception as e:
        print(f"âŒ Test segmentation error: {str(e)}")
        import traceback
        traceback.print_exc()
        return {
            "success": False,
            "error": str(e)
        }

@app.post("/api/report_detection")
async def report_detection(data: dict):
    """
    Receive detection report from Raspberry Pi and store in Firestore
    
    Expected JSON payload:
    {
        "source_device_id": "Pi-001-MainHall",
        "detection_type": "Motion",
        "confidence_score": 0.92,
        "summary_text": "Motion detected by front door.",
        "metadata": {
            "object_count": 2,
            "detection_algorithm": "DeepLabV3-ResNet101"
        },
        "image_data": "base64_encoded_image",
        "api_key": "your-api-key"
    }
    """
    try:
        print("ðŸ“¡ Received detection report from Raspberry Pi...")
        
        # Verify API key
        api_key = data.get("api_key", "")
        if api_key != MIRQAB_API_KEY:
            print("âŒ Invalid API key")
            return {
                "success": False,
                "error": "Invalid API key"
            }
        
        # Check if Firestore is initialized
        if not firestore_handler._initialized:
            print("âŒ Firestore not initialized")
            return {
                "success": False,
                "error": "Database not available"
            }
        
        # Extract report data
        report_data = {
            "source_device_id": data.get("source_device_id", "Unknown"),
            "detection_type": data.get("detection_type", "Unknown"),
            "confidence_score": float(data.get("confidence_score", 0.0)),
            "summary_text": data.get("summary_text", "Detection event"),
            "metadata": data.get("metadata", {})
        }
        
        # Optional: Upload image to Firebase Storage (TODO)
        # For now, we'll skip image storage to keep it simple
        # image_data = data.get("image_data")
        # if image_data:
        #     image_url = upload_to_firebase_storage(image_data, report_id)
        #     report_data["image_snapshot_url"] = image_url
        
        # Create report in Firestore
        report_id = firestore_handler.create_detection_report(report_data)
        
        if report_id:
            print(f"âœ… Detection report saved: {report_id}")
            return {
                "success": True,
                "report_id": report_id,
                "timestamp": datetime.now().isoformat(),
                "message": "Report saved successfully"
            }
        else:
            print("âŒ Failed to save report")
            return {
                "success": False,
                "error": "Failed to save report to database"
            }
    
    except Exception as e:
        print(f"âŒ Error processing Pi report: {str(e)}")
        import traceback
        traceback.print_exc()
        return {
            "success": False,
            "error": str(e)
        }

@app.post("/api/process_video")
async def process_video(file: UploadFile = File(...)):
    """
    Process video file with optimized frame-skipping segmentation overlay.
    Returns the processed video with red overlay on detected soldiers.
    Faster processing by analyzing every 3rd frame.
    """
    try:
        print("ðŸŽ¬ Starting fast video processing...")
        
        # Save uploaded video to temporary file
        with tempfile.NamedTemporaryFile(delete=False, suffix='.mp4') as temp_input:
            contents = await file.read()
            temp_input.write(contents)
            input_path = temp_input.name
        
        # Create output path
        output_path = tempfile.mktemp(suffix='_processed.mp4')
        
        # Open video
        cap = cv2.VideoCapture(input_path)
        
        # Get video properties
        fps = int(cap.get(cv2.CAP_PROP_FPS))
        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        
        print(f"ðŸ“Š Video info: {width}x{height} @ {fps}fps, {total_frames} frames")
        
        # âš¡ OPTIMIZATION: Process every 3rd frame for 3x speed
        frame_skip = 3
        print(f"âš¡ Fast mode: Processing every {frame_skip} frames (3x faster)")
        
        # Create video writer
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))
        
        frame_count = 0
        last_mask = None  # Cache last mask for skipped frames
        
        while cap.isOpened():
            ret, frame = cap.read()
            if not ret:
                break
            
            frame_count += 1
            
            try:
                # âš¡ OPTIMIZATION: Only process every Nth frame
                if frame_count % frame_skip == 1 or last_mask is None:
                    # Convert BGR to RGB for model
                    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                    pil_frame = Image.fromarray(frame_rgb)
                    
                    # Run segmentation (ignore instances for video processing)
                    mask, _ = model.predict(pil_frame)
                    last_mask = mask  # Cache for next frames
                    
                    # Create overlay
                    overlay_pil = overlay_mask_on_image(pil_frame, last_mask, alpha=0.5)
                else:
                    # âš¡ Reuse last mask for skipped frames (much faster)
                    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                    pil_frame = Image.fromarray(frame_rgb)
                    overlay_pil = overlay_mask_on_image(pil_frame, last_mask, alpha=0.5)
                overlay_frame = np.array(overlay_pil)
                
                # Convert RGB back to BGR for video writer
                overlay_bgr = cv2.cvtColor(overlay_frame, cv2.COLOR_RGB2BGR)
                
                # Write frame
                out.write(overlay_bgr)
                
            except Exception as e:
                print(f"âš ï¸ Warning: Error processing frame {frame_count}: {str(e)}")
                print(f"   Skipping overlay and writing original frame")
                # Write original frame if processing fails
                out.write(frame)
            
            # Progress update every 30 frames
            if frame_count % 30 == 0:
                progress = (frame_count / total_frames) * 100
                print(f"â³ Progress: {frame_count}/{total_frames} frames ({progress:.1f}%)")
        
        # Release resources
        cap.release()
        out.release()
        
        print(f"âœ… Video processing complete: {frame_count} frames processed")
        
        # Clean up input file
        os.unlink(input_path)
        
        # Return processed video
        return FileResponse(
            output_path,
            media_type="video/mp4",
            filename="segmented_video.mp4",
            headers={"Content-Disposition": "attachment; filename=segmented_video.mp4"}
        )
    
    except Exception as e:
        print(f"âŒ Video processing error: {str(e)}")
        import traceback
        traceback.print_exc()
        return {
            "success": False,
            "error": str(e)
        }

@app.post("/api/moraqib_query")
async def moraqib_query(query: str = Form(...)):
    """
    Moraqib RAG Assistant - Query detection reports using natural language
    
    This endpoint implements Retrieval-Augmented Generation (RAG):
    1. Retrieves relevant detection reports from Firestore
    2. Augments context with report data
    3. Generates natural language answer using OpenAI GPT-4 Turbo
    
    Strict Guardrails:
    - Only answers questions based on detection reports
    - Refuses general knowledge or off-topic questions
    - Always cites report IDs in responses
    
    Args:
        query: Natural language question (e.g., "How many detections yesterday?")
    
    Returns:
        JSON response with answer and metadata
    """
    try:
        print(f"\n{'='*60}")
        print(f"ðŸ”® MORAQIB RAG QUERY")
        print(f"{'='*60}")
        print(f"Question: {query}")
        
        # Check Firestore initialization
        if not firestore_handler.db:
            return {
                "success": False,
                "error": "Database not initialized. Please configure Firebase first."
            }
        
        # Process query through RAG pipeline
        result = await moraqib_rag.query(query)
        
        print(f"\n{'='*60}")
        print(f"âœ… MORAQIB RESPONSE READY")
        print(f"{'='*60}")
        
        return result
    
    except Exception as e:
        print(f"âŒ Moraqib endpoint error: {str(e)}")
        import traceback
        traceback.print_exc()
        
        return {
            "success": False,
            "question": query,
            "answer": "I'm sorry, I encountered an error processing your question.",
            "error": str(e)
        }

@app.get("/api/fetch-image-base64")
async def fetch_image_base64(url: str):
    """
    Fetch an image from Firebase Storage URL and return as base64
    This bypasses CORS issues when generating PDFs
    """
    try:
        import requests
        from urllib.parse import urlparse, unquote
        
        print(f"Fetching image from URL: {url}")
        
        # Check if it's a Firebase Storage URL
        if 'storage.googleapis.com' in url or 'firebasestorage.googleapis.com' in url:
            print("Detected Firebase Storage URL, using Firebase Admin SDK...")
            
            # Extract the file path from the URL
            # URL format: https://storage.googleapis.com/bucket-name/path/to/file.jpg
            parsed_url = urlparse(url)
            path_parts = parsed_url.path.strip('/').split('/', 1)
            
            if len(path_parts) >= 2:
                bucket_name = path_parts[0]
                file_path = unquote(path_parts[1])
                
                print(f"Bucket: {bucket_name}, File path: {file_path}")
                
                # Use Firebase Admin SDK to download the file
                from firebase_admin import storage
                
                bucket = storage.bucket(bucket_name)
                blob = bucket.blob(file_path)
                
                # Download the image
                image_bytes = blob.download_as_bytes()
                
                # Convert to base64
                image_base64 = base64.b64encode(image_bytes).decode('utf-8')
                
                # Create data URL
                data_url = f"data:image/jpeg;base64,{image_base64}"
                
                print(f"Successfully fetched image via Firebase SDK, size: {len(image_base64)} bytes")
                
                return JSONResponse(content={
                    "success": True,
                    "base64": data_url
                })
        
        # Fallback to regular HTTP request for non-Firebase URLs
        print("Using regular HTTP request...")
        response = requests.get(url, timeout=10)
        response.raise_for_status()
        
        # Convert to base64
        image_base64 = base64.b64encode(response.content).decode('utf-8')
        
        # Determine content type
        content_type = response.headers.get('Content-Type', 'image/jpeg')
        
        # Create data URL
        data_url = f"data:{content_type};base64,{image_base64}"
        
        print(f"Successfully fetched image, size: {len(image_base64)} bytes")
        
        return JSONResponse(content={
            "success": True,
            "base64": data_url
        })
        
    except requests.exceptions.RequestException as e:
        print(f"Error fetching image: {str(e)}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=400, detail=f"Failed to fetch image: {str(e)}")
    except Exception as e:
        print(f"Unexpected error: {str(e)}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"Server error: {str(e)}")

if __name__ == "__main__":
    import uvicorn
    print("ðŸš€ Starting Mirqab Backend Server...")
    uvicorn.run(app, host="0.0.0.0", port=8000)

